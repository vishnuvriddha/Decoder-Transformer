{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bm25s\n",
    "import re\n",
    "import sys\n",
    "from io import StringIO\n",
    "import platform\n",
    "import os\n",
    "import ollama\n",
    "from typing import Dict, Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Search Engine with RAG abilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        self.key = \"APIKEY\"\n",
    "        self.cx = 'CXKEY' \n",
    "\n",
    "    def _search_google_snippets(self ,query, num_results=3):\n",
    "\n",
    "        base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        \n",
    "        params = {\n",
    "            'q': query,\n",
    "            'key': self.key,\n",
    "            'cx': self.cx,\n",
    "            'num': num_results\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            results = response.json().get('items', [])\n",
    "            links = [item['link'] for item in results]\n",
    "            \n",
    "            return links\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return []\n",
    "        \n",
    "    def _extract_paragraph_text(self, urls):\n",
    "\n",
    "        urls_dtype, urls_len = type(urls), len(urls)\n",
    "\n",
    "        if urls_len == 0:\n",
    "            return None\n",
    "        \n",
    "        if urls_dtype == str:\n",
    "            urls = list([urls])\n",
    "\n",
    "        all_paras = ' '\n",
    "        for url in urls:\n",
    "            response = requests.get(url)\n",
    "            html_content = response.text\n",
    "\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p')\n",
    "            paragraph_text = ' '.join(p.get_text(strip=True) for p in paragraphs)\n",
    "\n",
    "            all_paras +='\\n'\n",
    "            all_paras +=paragraph_text\n",
    "        \n",
    "        return all_paras\n",
    "    \n",
    "    def _perform_rag_bm25(self, query, full_data):\n",
    "\n",
    "        # Create the corpus with a simple regex split:\n",
    "        corpus = re.split(r'(?<=[.!?])\\s+', full_data)\n",
    "\n",
    "        # Tokenize the corpus:\n",
    "        corpus_tokens = bm25s.tokenize(corpus)\n",
    "\n",
    "        # Create the BM25s model to index the corpus\n",
    "        # You may not index if you dont want to since it takes more memory, but save search time later.\n",
    "        retriever = bm25s.BM25()\n",
    "        retriever.index(corpus_tokens)\n",
    "\n",
    "        # tokenize the query:\n",
    "        query_tokens = bm25s.tokenize(query)\n",
    "\n",
    "        # Get the top-k results\n",
    "        results, scores = retriever.retrieve(query_tokens, corpus, k = 5)\n",
    "\n",
    "        # Now append the results in an enumerated plaintext format:\n",
    "        context = \"\"\n",
    "        for i in range(results.shape[1]):\n",
    "            doc = results[0, i]\n",
    "            context += f\"{i+1}: {doc}\\n\"\n",
    "\n",
    "        return context\n",
    "    \n",
    "    def execute(self, query):\n",
    "\n",
    "        # Step 1: send the query to google to fetch the most matching links    \n",
    "        links = self._search_google_snippets(query)\n",
    "        \n",
    "        # Step 2: Extract text data from <p> tags from those links\n",
    "        full_data = self._extract_paragraph_text(links)\n",
    "\n",
    "        # # Step 3: Save the Data (Just For Fun)\n",
    "        # with open(\"Out.txt\", 'w', encoding= 'utf-8') as f:\n",
    "        #     f.write(full_data)\n",
    "\n",
    "        # Step 4: Now, using the data as corpus, re-run the query against i\n",
    "        context = self._perform_rag_bm25(query, full_data)\n",
    "\n",
    "        self.context = context\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Fixing Coding Agent\n",
    "\n",
    "1. Run an LLM instance\n",
    "2. Extract code with regex parsing\n",
    "3. Send code to a subprocess to execute it\n",
    "4. Fetch output/Error and return it back to the LLM (VIA SYSTEM PROMPT)\n",
    "5. Put 2-4 on Loop until desired output has been achieved.\n",
    "6. Return final code\n",
    "\n",
    "Additional tasks:\n",
    "1. Give it a filepath and make it change the code base within it.\n",
    "2. Create a critic that asks for required paths for any given task as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_blocks(text):\n",
    "    pattern = r'```(?:\\w+\\n)?(.+?)```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return [match.strip() for match in matches]\n",
    "\n",
    "def execute_code(code_string: str):\n",
    "    \"\"\"Returns Boolean, Evaluation String\"\"\"\n",
    "    # Redirect stdout and stderr\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    redirected_output = sys.stdout = StringIO()\n",
    "    redirected_error = sys.stderr = StringIO()\n",
    "\n",
    "    output = \"\"\n",
    "    error = None\n",
    "\n",
    "    try:\n",
    "        # Execute the code\n",
    "        exec(code_string)\n",
    "        output = redirected_output.getvalue()\n",
    "        error = redirected_error.getvalue()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "    finally:\n",
    "        # Restore stdout and stderr\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "\n",
    "    return output, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a system prompt:\n",
    "\n",
    "SYSTEM_MESSAGE = f\"\"\"\n",
    "You are a fast, efficient AI assistant specialized in analyzing terminal history and providing solutions. Your task is to:\n",
    "\n",
    "1. Scan the provided message history.\n",
    "2. Identify the most recent error or issue or request.\n",
    "3. Take a deep breath, and thoughtfully, carefully determine the most likely solution or debugging step.\n",
    "4. Respond with a VERY brief explanation followed by a markdown code block containing a PYTHON CODE to solve the issue.\n",
    "5. Make sure to call the functions or classes you write in the Python Code as well, in the same code.\n",
    "\n",
    "Rules:\n",
    "- DO NOT WRITE PYTHON at the TOP when returning PYTHON CODE\n",
    "- Keep any explanatory text extremely brief and concise.\n",
    "- Place explanatory text before the code block.\n",
    "- NEVER USE COMMENTS IN YOUR CODE.\n",
    "- Ensure that your code follows given CWD and System\n",
    "- If previously given code attempted to fix the issue and failed, learn from them by proposing a DIFFERENT code.\n",
    "- Focus on the most recent error, ignoring earlier unrelated code.\n",
    "- The error may be as simple as a spelling error, or as complex as requiring tests to be run, or code to be find-and-replaced.\n",
    "- Prioritize speed and conciseness in your response. Don't use markdown headings. Don't say more than a sentence or two. Be incredibly concise.\n",
    "\n",
    "User's System: {platform.system()}\n",
    "CWD: {os.getcwd()}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Session State ...\n",
      "Select Model: phi3:latest\n",
      "System Message Initialized ...\n"
     ]
    }
   ],
   "source": [
    "# Lets define the messages chain:\n",
    "messages = []\n",
    "print(\"Created Session State ...\")\n",
    "\n",
    "models = [model[\"name\"] for model in ollama.list()[\"models\"]]\n",
    "model = models[2]\n",
    "\n",
    "print(\"Select Model:\", model)\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": SYSTEM_MESSAGE})\n",
    "\n",
    "print(\"System Message Initialized ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:\n",
      "\n",
      " You are still wrong, do it by making a class that writes an algorithm to get a random number instead of using the random library \n",
      "\n",
      "\n",
      "==== ASSISTANT ================\n",
      " ```python\n",
      "class RandomNumberGenerator:\n",
      "    def __init__(self):\n",
      "        self.seed = int((datetime.datetime.now() - datetime.datetime(1970, 1, 1)).total_seconds()) % (2**32) # Seed calculation from current time\n",
      "    \n",
      "    @staticmethod\n",
      "    def _getRandomIndex():\n",
      "        return random.randint(0, self.seed) if not hasattr(self,'random') else getattr(random, 'randrange')(1, self.seed + 2 - len(str(self.seed))) # Secure pseudo-random index generation with seed modification for reproducibility\n",
      "        \n",
      "    def generateRandomNumber(self):\n",
      "        if not hasattr(self,'r'):\n",
      "            return None\n",
      "        r = getattr(random, 'randrange') if self.use_secure else _getRandomIndex # Lazy initialization and secure random fallback using os.urandom for seed in the next step of optimization\n",
      "        self.r = [int((1 - (i / float(self.seed))) ** 0.5) * r % self.seed + i if not hasattr(self,'random') else int(str(r), base=2) // len(str(self.seed)) for _ in range(4)] # Random number generation using bitwise operations on the secure random seed\n",
      "        return [n for n,_ in sorted(enumerate(self.r), key=lambda x:x[1])] \n",
      "    \n",
      "    def useSecureRandom(self, flag):\n",
      "        if not hasattr(self,'use_secure'): self.use_secure = False # Initialization of secure random usage flag for reproducibility and security enhancements in the next step of optimization with os module fallback option \n",
      "        \n",
      "randomNumberGen = RandomNumberGenerator()\n",
      "print([n for n, _ in sorted(enumerate(randomNumberGen.generateRandomNumber()), key=lambda x:x[1])]) # Output random numbers from a class-based generator using lazy initialization and bitwise operations on the seed integer with secure fallback option \n",
      "```\n",
      "Error\n",
      "==== ASSISTANT ================\n",
      " ```python\n",
      "import os, time # Import necessary modules for date-time calculation without third party libraries and system file access (to maintain a self-contained script)\n",
      "class RandomNumberGenerator:\n",
      "    def __init__(self):\n",
      "        seconds_since_epoch = int(time.mktime((os.gethostyear(), os.gethostmon(), 0,)*3 + (int(os.getlogin()),))) # Secure and reproducible seed calculation from current time using system host information to avoid third-party library dependency\n",
      "        self.seed = seconds_since_epoch % (2**32) - int(seconds_since_epoch / 45096 * (2**32)) + os.urandom((8*(1+len(str(self.seed))))//8)[::-1].hex().encode() # Secure and reproducible seed calculation using host system time, integer operations for pseudo randomness optimization with bitwise operation on the secure random byte sequence fallback option\n",
      "        self.r = [0] * 4 # Initialize list of four integers representing our 'random' numbers initially set to zero (for lazy initialization)  \n",
      "    \n",
      "    @staticmethod\n",
      "    def _getRandomIndex():\n",
      "        return int(os.urandom((16//8))[::-1].hex(), base=16) if not hasattr(self,'r') else self.seed % len(str(self.seed)) # Secure pseudo-random index generation with seed modification for reproducibility using system byte sequence fallback option\n",
      "        \n",
      "    def generateRandomNumber(self): \n",
      "        r = [int((1 - (i / float(len(str(self.seed))) ** 0.5) * int(_getRandomIndex()) % len(str(self.seed)) + i) for _ in range(4)] if not hasattr(self,'r') else self.r # Random number generation using bitwise operations on the secure random seed with lazy initialization\n",
      "        return r[::-1] \n",
      "    \n",
      "    def useSecureRandom(self, flag):\n",
      "        if not getattr(self,'use_secure',False) and 'secured' in str(flag).lower(): self.use_seed = os.urandom((8*(1+len(str(getattr(self, 'seed', 0))))//8)).hex().encode() # Initialization of secure random usage flag for reproducibility enhancements with system byte sequence fallback option\n",
      "        \n",
      "randomNumberGen = RandomNumberGenerator()\n",
      "print([n for n, _ in sorted(enumerate(randomNumberGen.generateRandomNumber()), key=lambda x:x[1])]) # Output random numbers from a class-based generator using lazy initialization and bitwise operations on the secure seed byte sequence with system file access (to maintain self-contained script)\n",
      "```\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "def chat_and_execute(query, messages, model):\n",
    "\n",
    "    # Get user input\n",
    "    print(\"query:\\n\\n\", query, \"\\n\\n\")\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Chat with LLM\n",
    "    response = ollama.chat(model, messages)\n",
    "    assistant_response = response['message']['content']\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    print(\"==== ASSISTANT ================\")\n",
    "\n",
    "    print(assistant_response)\n",
    "    \n",
    "    # Parse code from response\n",
    "    code = extract_code_blocks(assistant_response)[0]\n",
    "    \n",
    "    if code:\n",
    "        # Execute code\n",
    "        result, error = execute_code(code)\n",
    "        \n",
    "        while error:\n",
    "            # Code execution failed, ask LLM to refine\n",
    "\n",
    "            print('Error', error)\n",
    "            outstr = f\"\"\"\n",
    "                The code execution failed with the following error: {error}.\n",
    "                Please rewrite the code to fix this issue.\"\"\"\n",
    "            messages.append({\"role\": \"user\", \"content\": outstr})\n",
    "            response = ollama.chat(model, messages)\n",
    "            assistant_response = response['message']['content']\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            print(\"==== ASSISTANT ================\")\n",
    "            print(assistant_response)\n",
    "\n",
    "            code = extract_code_blocks(assistant_response)[0]\n",
    "            if code:\n",
    "                result, error = execute_code(code)\n",
    "            else:\n",
    "                error = None\n",
    "        else:\n",
    "            print(\"Code executed successfully.\")\n",
    "            print(\"Result:\", result)\n",
    "    \n",
    "    print(\"Assistant:\", assistant_response)\n",
    "\n",
    "chat_and_execute(\"You are still wrong, do it by making a class that writes an algorithm to get a random number instead of using the random library\", messages, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
